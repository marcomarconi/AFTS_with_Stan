---
title: "Dynamic Linear Models with Switching in Stan"
output: html_document
date: "2022-10-30"
---

---
output:
  html_document: default
  pdf_document: default
---

```{=html}
<style type="text/css">
  body{
  font-size: 14pt;
}
</style>
```
![](images/flu.png)

```{r setup, include=FALSE,echo=FALSE}
require(knitr)
knitr::opts_chunk$set(echo = TRUE,fig.width=14,fig.height=7)
read_chunk('common.R')
read_chunk('flu.R')
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

```

In this post we are trying to reproduce Example 6.22 presented in the book "Time Series Analysis and its Applications with R examples", by Robert H. Shumway and David S. Stoffer. We will analyze the U.S. monthly pneumonia and influenza mortality using Dynamic Linear Models with Switching. This kind of models attempt to generalize state space models to include the possibility of regime changes occurring over time. The idea is to use hidden markov models (HMM) to marginalize the hidden discrete states allowing the state space model to behave differently depending on the underlying unobserved state. The example in the book utilizes the exact likelihood, but in this post we will try to express the model explicitly with Stan. For an example of state-space model with Stan see Juho Kokkala's blog post <http://www.juhokokkala.fi/blog/posts/kalman-filter-style-recursion-to-marginalize-state-variables-to-speed-up-stan-inference/> or Jeffrey B. Arnold's library <https://jrnold.github.io/ssmodels-in-stan/filtering-and-smoothing.html>, while an example of HMM can be found in Stan's manual <https://mc-stan.org/docs/stan-users-guide/hmms.html>.

```{r load_flu, message=FALSE, warning=FALSE}
require(tidyverse)
require(rstan)
require(mvtnorm)
require(posterior)
require(cmdstanr)
```

Let's have a look at the date representing mortality rate from 1968 to 1978:

```{r plot_flu, message=FALSE, warning=FALSE}
```

The model consists of three structural components. The first component is an AR(2) process chosen to represent the periodic (seasonal) component of the data:

$$ 
x_{t1} = \alpha_{1}x_{t-1,1} + \alpha_{2}x_{t-2,1} + w_{t1}
$$ where $w_{t1}$ is white noise with variance = $\sigma_{1}^2$.

The second component is an AR(1) process with a nonzero constant term, representing the sharp rise in the data during an epidemic:

$$ 
x_{t2} = \beta_{0} + \beta_{1}x_{t-1,2} + w_{t2}
$$ where $w_{t2}$ is white noise with variance = $\sigma_{2}^2$. The third component is a fixed trend component:

$$ 
x_{t3} = x_{t-1,3} + w_{t3}
$$

In the book this process is assumed to be deterministic because estimation was unstable, we will try try to estimate it nonetheless. The model can be expressed in state-space form as:

$$
\begin{pmatrix} x_{t,1} \\ x_{t-1,1} \\ x_{t,2} \\ x_{t,3} \end{pmatrix} = \begin{bmatrix} \alpha_{1} & \alpha_{2} & 0 & 0 \\ 1 & 0 & 0 & 0 \\ 0 & 0 &  \beta_{1} & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} \begin{pmatrix} x_{t-1,1} \\ x_{t-2,1} \\ x_{t-1,2} \\ x_{t-1,3} \end{pmatrix} +  \begin{pmatrix} 0 \\ 0 \\  \beta_{0} \\ 0 \end{pmatrix} + \begin{pmatrix} w_{t1} \\ 0 \\  w_{t2} \\ 0 \end{pmatrix}
$$

The observation equation is:

$$ 
y_{t} = A_{t}x_{t} + v_{t}
$$

We want periods of normal influenza mortality (regime 1) are modeled as:

$$ 
y_{t} = x_{t1} + x_{t3} + v_{t}
$$

while during epidemics (regime 2) mortality is modelled as:

$$ 
y_{t} = x_{t1} + x_{t2} + x_{t3} + v_{t}
$$

Therefore, the matrix A can take two forms depending on the regime: [1,0,0,1] for no epidemic, and [1,0,1,1] for epidemic.

We decided to model the process in Stan as follows:

```{stan code=readLines("models/Misc/flu.stan"), attr.source='.numberLines',  output.var='priors', eval = FALSE, tidy = FALSE}

```

The code seems to be very involved but you can see that apart for a large amount of variables declared, most of the code is mode of the main loop for the kalman filter and the hmm marginalization. Notice that the Kalman filter loop is run twice for both values of matrix A representing the two possible regimes, therefore we need to have two value for each variable of the Kalman filter, as you can see in the declaration at the top. Later during the HMM forward algorithm we calculate the probability of each regime (which differ only for the value of A).

```{r fit_flu, message=FALSE, warning=FALSE, echo=FALSE}
```

``` r
m <- cmdstan_model("models/Misc/flu.stan")
fit <- m$sample(data=list(N=length(flu), y=c(0, diff(as.vector(flu))), m0=rep(0, 4), P0=diag(c(1,1,1,1))), parallel_chains = 4, cores = 4,iter_warmup = 250, iter_sampling = 250)
```

Parameters estimations are vaguely close to the ones in the book, we additionally obtain transition probabilities estimations:

```{r print_flu, message=FALSE, warning=FALSE}
```

Regime estimation are reasonable, even if not so good as in the book:

```{r regimes_flu, message=FALSE, warning=FALSE}
```

To obtain the estimation of the final filtered states, we get the filtered states for the two regimes and we calculated the average weighted using the probability for each regimes:

```{r states_flu, message=FALSE, warning=FALSE}
```

Estimation for the trend process seems to be strongly affected by the epidemic oscillation, unlike the state obtained in the book. It is possible that additional precautions are needed in the definition of our model to better match the results. We finally show one-month-ahead predictions with the variability (2\*innovations-variance):

```{r mu_flu, message=FALSE, warning=FALSE}
```
